\chapter{Evaluation}
\label{chap:evaluation}
\THsec{Changes to Sniper}{chSniper}
In this work we will focus more on the traces which also can be generated by Sniper.
Traces are simply a list of the CPU instructions that was simulated, we come back
to this in 3.4. \fixme The trace is what we bring from Sniper to the next step in this work
flow. Some minor updates has been done to parts of Sniper that prints the trace:
\begin{itemize}
\item Writing the start PC (program counter) first in the trace.
\item Writing the length of the previous instruction to gather with every instruction.
\item Prints the target PC of a branch together with a ”*” if the branch is taken.
\item Implementing a new flag,\emph{ –insert-clear-stat-by-icount=n}, where n is a positive
integer, which leaves a line with just a ”C” after n lines of instructions.	
\end{itemize}

\THsec{ Configuration}{conf}
Configurations is a list of keys with assigned values that sets out the characteristics
for the CPU to be simulated. Some examples can be the number and sizes of
cashes, the sizes of buffers, number of cores, frequency and a lot more. The PROCESSOR
STORE PREFETCH key is the one used to set the prefetch policy. Another
key to keep track of is SIMULATION BENCHMARK which holds the name of the
simulation benchmark program so it can be added to the stats-file (see 2.2.3 \fixme ). Between
the different simulations only the values of the two described keys is changed,
the rest stays the same and sets out the CPU architecture which will be described in
the following subsection.
\THsec{CPU architecture}{arc}
The CPU design simulated for this master thesis (the numbers introduced in figure
2.1 \fixme ) was the one used in the paper ”Non-Speculative Load-Load Reordering in
TSO” [?].\fixme You can read more about it under related work 1.3.\fixme they claim that the
architecture follows the Bell-Lipasti design.
\THsec{Trace: Interface Sniper-GEMS}{trace}
A CPU cannot read program languages like C or Java directly. Instead the CPU
has a set of instructions that it can compute, called instruction set. The instruction
set can differ from one type of CPU to another, but three types of instructions that
can been found in some way in any instruction set are; arithmetical operations such
as, addition, subtraction, multiplication and division, memory instructions such as,
loads and stores, and branches. Branches tells the CPU if it should jump to another
instruction or not. Consider a for-loop, that loop will be represented by a branch
instruction telling the CPU if it should jump back to the beginning of the loop or
continue on below it. When compiling a C or Java file you end up with a binary file
that contains the translation from the source code to a particular instruction set, this
is the file you use to run the application in question. A trace file is a human readable
”binary file”.
\\\\
PC stands for program counter and it keeps track of which instruction in a program
to be executed next, then taking a branch the CPU changes the PC to the one
of the target instructions from a branch and carries on from that.
\\\\
The trace files used here will cover more details regarding memory instructions,
that is loads and stores. Thats why a trace file has a linebreak after each memory
instruction. Below follows a number of examples on lines from traces which will be
explained and translated to English.
\begin{figure}[h]
\begin{lstlisting}[frame=single]  
4030fc
\end{lstlisting}
\centering
 \emph{The first line of a trace is the starting PC}
  \caption{Trace example: Starting PC}
\end{figure}

The trace starts with the value of the starting PC in hexadecimal-format from now on the differentiation of the PC from on instruction to the next is write in decimalform
along with the instruction. Note that the second instruction shows the length
(the change to the PC) of the first one, and so on.

\begin{figure}[h]
\begin{lstlisting}[frame=single]  
0 4 L4 ee7e220 4
\end{lstlisting}
\centering
\emph{Two anonymous functions, both with length four followed by a load of 4
bytes from memory address ee7e220}
  \caption{Trace example: Anonymus functions and a Load}
\end{figure}

The 0 and the 4 denotes two anonymous functions (we care more about loads,
stores and branches). Since the first digit denotes the size of the previous instruction
we know that the two anonymous function both have the size of four (the ”4” after
the first space and the ”4” after the ”L”). The ”L” tells us that the instruction is
a load instruction and we load from the hexadecimal memory address ee7e220. The
number of bytes to be loaded is written after the last space, four in this case.

\begin{figure}[h]
\begin{lstlisting}[frame=single]  
0d1d3 b4d1t99* S99 7fff8368acd8 8
\end{lstlisting}
\centering
\emph{A anonymous function of size 4, that are dependent of the the first
and the third instruction prior to this. Then a taken branch to PC+99 ahead with
a dependency to the prior instruction where we a store of 8 bytes to the address
7fff8368acd8.}
  \caption{Trace example: Branch and store}
\end{figure}

Given the previous examples this line start with one anonymous instruction of
size four. In this case the first instruction are also dependent of the result from the
two previous instructions, this is denoted by the two ”d”s before the first space. The
digit after each ”d” points out how many instructions before the dependent one are,
here one and three. The next instruction starts with a ”b” which tells us that it is a
branch. The branch are dependent of the instruction before, the anonymous one that
was discussed in the beginning of this example. The ”t” denotes the branch target
follow by the difference between the current PC and the target address. Here 99
should be added to the PC if taken. The ”*” denotes that the branch is taken. After
that there is an ”S”, namely a store instruction. Here one can once again see that the
branch is taken since the difference from the branch instruction is 99 (directly after
the ”S”) as the branch target. A store interaction follows the same pattern as a load,
here it stores 8 bytes to the memory address 7fff8368acd8.

\begin{figure}[h]
\begin{lstlisting}[frame=single]  
0m3 b4t-166* L-166 7ff8368acd8 8
\end{lstlisting}
\centering
\emph{A anonymous instruction of size 4 that are depend of data from memory
that are retrieved in the third prior instruction. After that there is a branch with a
negative PC difference (-166) as the target which leads to a load of 8 bytes to the
address 7fff8368acd8.}
  \caption{Trace example: Branch to a previous instruction}
\end{figure}

In this example we only have two new things to cover, the rest have been covered
in the previous examples. The ”m” denotes a memory dependency, some data that
are to be loaded in the third previous instruction. The ”d”’s are dependencies on
data to be computed by the instruction in question and the ”m”’s are data that is
needed to be loaded into the CPU. The next thing to cover is that we here have a
negative PC difference for the target address. We now have all knowledge to directly
translate the line to English: A anonymous instruction of size 4 that are dependent of
data from memory that are retrieved in the third prior instruction. After that there
is a branch with a negative PC difference (-166) as the target which leads to a load
of 8 bytes to the address 7fff8368acd8.

\THsec{Metrics for evaluation}{meEval}
During this thesis a python script was written to automatizes the run of the simulation
on every sub folder in a predefined folder (all sub folders have to contain traces
from a benchmark program). In the source code there is a predefined array with the
names of the prefetch policies you want to run. The script will then run GEMS on
every trace with every store prefetch policy and name the stat-file in the following
way: [name on benchmark] [name on store prefetch policy].stats
 \\ \\
The script will also generate the results by reading some values from every statsfile,
the values to be read are hard coded into an array. After collecting all these
values from every file, the values from all benchmarks for every store policy will be
summed. The values for NoPrefetch will be set to 100\% and the other will get their
percentages based on that. This percentages will the be plotted into bar charts (which
can be find in the results).

\THsub{Energy graphs}{energy}
Table \ref{tab:energy} lists the energy consumption for accessing our three caches and the network
flits which are the energy needed for transmission of a data unit between caches and
the pipeline. One flits for transmission of control messages and five for data [12] \fixme
In order to retrieve the numbers for the caches we use the CACTI-P tool [11] \fixme to
estimate the power consumption of the different cache structures assuming a 22 nm
technology node. To estimate the dynamic energy consumption of the interconnection
network, we assume that it is proportional to the data transferred [4] \fixme and that each
flit transmitted through the network consumes the same amount of energy as reading
one word from an L1 cache each time that it crosses a link (link and router energy).
These number is used by the python script 3.5 \fixme to generate the power graphs that can be seen in the results 5 \fixme.
\begin{table}[h]
	\begin{centering}
		\begin{tabular}{ |c|c| }
			\hline
			CPU part & Energy [nJ] \\ \hline
			Accessing L0 & 0.013343 \\ \hline
			Accessing L1 & 0.0214929 \\ \hline
			Accessing L2 & 0.0454353 \\ \hline
			Network flit & 0.0033357 \\ \hline
		\end{tabular}
		\caption{Energy measurements for different CPU parts.}
		\label{tab:energy}
	\end{centering}
\end{table}








